# 技術実装ガイド

## アーキテクチャ概要

### レイヤー構造
```
┌─────────────────────────────────────────────────────────────┐
│                      Presentation Layer (UI)                 │
│  - PyQt6ベースのGUIコンポーネント                              │
│  - タイムライン、ビューア、マスクエディタ                        │
└─────────────────────────────────────────────────────────────┘
                              ↕
┌─────────────────────────────────────────────────────────────┐
│                   Application Core (Python)                  │
│  - プロジェクト管理、タスクスケジューラ                          │
│  - Undo/Redo、プラグイン管理、ロギング                         │
└─────────────────────────────────────────────────────────────┘
                              ↕
┌─────────────────────────────────────────────────────────────┐
│                      Domain Services                         │
│  - Media I/O、マスク編集、アラート                             │
│  - エフェクト、品質検証、学習データ出力                          │
└─────────────────────────────────────────────────────────────┘
                              ↕
┌─────────────────────────────────────────────────────────────┐
│                    Infrastructure Layer                      │
│  - FFmpeg、GPU処理、メモリ管理                                │
└─────────────────────────────────────────────────────────────┘
```

## Hexagonal Architecture実装ガイド

### Port/Adapterパターンの実装

Hexagonal Architecture（ヘキサゴナルアーキテクチャ）を採用、ビジネスロジックを外部技術から独立。

#### ディレクトリ構造

```
src/
├── domain/              # ドメイン層（ビジネスロジック）
│   ├── dto/            # Data Transfer Objects
│   │   ├── __init__.py
│   │   ├── frame_dto.py
│   │   ├── mask_dto.py
│   │   └── project_dto.py
│   ├── ports/          # インターフェース定義
│   │   ├── primary/    # 入力ポート
│   │   │   ├── __init__.py
│   │   │   ├── project_service.py
│   │   │   └── video_editor.py
│   │   └── secondary/  # 出力ポート
│   │       ├── __init__.py
│   │       ├── video_reader.py
│   │       └── effect_engine.py
│   └── services/      # ドメインサービス
│       ├── __init__.py
│       ├── project_manager.py
│       └── mask_editor.py
├── adapters/           # アダプター層
│   ├── primary/        # UI、API等
│   │   ├── pyqt_ui/
│   │   └── rest_api/
│   └── secondary/      # 外部リソース
│       ├── pyav_video_reader.py
│       ├── cpp_video_reader.py
│       └── opencv_effect_engine.py
└── infrastructure/     # インフラ層
    ├── di_container.py
    └── config_loader.py
```

### DTO/VO実装パターン

外部ライブラリの型を境界で変換し、ドメイン層を純粋に。

#### DTO定義例

```python
# src/domain/dto/frame_dto.py
from dataclasses import dataclass
from typing import Optional
import numpy as np

@dataclass(frozen=True)
class FrameDTO:
    """フレームデータ転送オブジェクト
    
    すべての値は不変（immutable）として扱う
    """
    data: np.ndarray      # RGB24形式固定
    pts: int             # マイクロ秒単位
    width: int
    height: int
    frame_number: int
    
    def __post_init__(self):
        """検証"""
        assert self.data.shape == (self.height, self.width, 3)
        assert self.data.dtype == np.uint8
        assert self.pts >= 0
        assert self.frame_number >= 0

# src/domain/dto/video_metadata_dto.py
@dataclass(frozen=True)
class VideoMetadataDTO:
    """ビデオメタデータ転送オブジェクト"""
    width: int
    height: int
    fps: float
    frame_count: int
    duration: float  # 秒単位
    codec: str
    colorspace: str = "bt709"
    bit_depth: int = 8
    has_audio: bool = False
```

#### アダプターでの変換例

```python
# src/adapters/secondary/pyav_video_reader.py
import av
from ...domain.ports.secondary import IVideoReader
from ...domain.dto import FrameDTO

class PyAVVideoReader:
    """PyAVアダプター実装"""
    
    def read_frame(self, index: int) -> FrameDTO:
        # PyAV固有の型
        av_frame = self._decode_frame(index)
        
        # DTOへ変換（境界での型変換）
        numpy_data = av_frame.to_ndarray(format='rgb24')
        
        return FrameDTO(
            data=numpy_data,
            pts=av_frame.pts,
            width=av_frame.width,
            height=av_frame.height,
            frame_number=index
        )
```

### Port定義パターン

Pythonの`Protocol`を使用して、実装に依存しないインターフェースを定義します。

```python
# src/domain/ports/secondary/video_reader.py
from typing import Protocol, Iterator, Optional
from ...dto import FrameDTO, VideoMetadataDTO

class IVideoReader(Protocol):
    """ビデオ読み込みポート
    
    実装クラスはこのインターフェースを満たす必要がある
    """
    def open(self, path: str) -> VideoMetadataDTO:
        """ビデオファイルを開く"""
        ...
    
    def read_frame(self, index: int) -> Optional[FrameDTO]:
        """指定フレームを読み込む"""
        ...
    
    def read_frames(self, start: int = 0, end: Optional[int] = None) -> Iterator[FrameDTO]:
        """フレーム範囲を読み込む"""
        ...
    
    def close(self) -> None:
        """リソースを解放"""
        ...

# src/domain/ports/primary/project_service.py
class IProjectService(Protocol):
    """プロジェクト管理サービスポート"""
    
    async def create_project(self, name: str) -> ProjectDTO:
        """新規プロジェクト作成"""
        ...
    
    async def save_project(self, project: ProjectDTO, path: str) -> None:
        """プロジェクト保存"""
        ...
    
    async def load_project(self, path: str) -> ProjectDTO:
        """プロジェクト読み込み"""
        ...
```

### DIコンテナ実装

依存性注入により、実装の切り替えを容易。

```python
# src/infrastructure/di_container.py
from typing import Dict, Type, Callable, Any, TypeVar, Generic
from collections.abc import Mapping

T = TypeVar('T')

class DIContainer:
    """型安全な依存性注入コンテナ"""
    
    def __init__(self):
        self._factories: Dict[Type, Callable[[DIContainer], Any]] = {}
        self._singletons: Dict[Type, Any] = {}
        self._config: Mapping[str, Any] = {}
    
    def register(
        self, 
        interface: Type[T], 
        factory: Callable[['DIContainer'], T],
        singleton: bool = False
    ) -> None:
        """インターフェースに対するファクトリーを登録
        
        Args:
            interface: 登録するインターフェース型
            factory: インスタンスを生成するファクトリー関数
            singleton: シングルトンとして管理するか
        """
        self._factories[interface] = (factory, singleton)
    
    def resolve(self, interface: Type[T]) -> T:
        """インターフェースの実装を解決
        
        Args:
            interface: 解決するインターフェース型
            
        Returns:
            インターフェースの実装インスタンス
        """
        if interface in self._singletons:
            return self._singletons[interface]
        
        if interface not in self._factories:
            raise ValueError(f"No factory registered for {interface.__name__}")
        
        factory, is_singleton = self._factories[interface]
        instance = factory(self)
        
        if is_singleton:
            self._singletons[interface] = instance
        
        return instance
    
    def get_config(self, key: str, default: Any = None) -> Any:
        """設定値を取得"""
        return self._config.get(key, default)
```

### 設定ベースの実装切り替え

```python
# src/infrastructure/container_config.py
from ..adapters.secondary import PyAVVideoReader, CppVideoReader
from ..domain.ports.secondary import IVideoReader

def configure_production(container: DIContainer, config: Dict[str, Any]):
    """本番環境用の設定"""
    container._config = config
    
    # VideoReaderの登録（設定に基づいて実装を選択）
    backend = config.get('video_reader.backend', 'pyav')
    
    if backend == 'cpp':
        container.register(
            IVideoReader,
            lambda c: CppVideoReader(
                threads=c.get_config('video_reader.threads', 4)
            ),
            singleton=False
        )
    else:
        container.register(
            IVideoReader,
            lambda c: PyAVVideoReader(),
            singleton=False
        )

# config/settings.yaml
video_reader:
  backend: "cpp"  # "pyav" or "cpp"
  threads: 4
  
effect_engine:
  backend: "python"  # "python" or "cpp"
  use_gpu: false
```

### C++ Adapter実装例

pybind11を使用してPythonインターフェースを満たすC++実装を作成。

```cpp
// src/cpp_extensions/video_reader.cpp
#include <pybind11/pybind11.h>
#include <pybind11/numpy.h>
#include <pybind11/stl.h>

namespace py = pybind11;

class CppVideoReader {
private:
    AVFormatContext* format_ctx_ = nullptr;
    AVCodecContext* codec_ctx_ = nullptr;
    
public:
    py::dict open(const std::string& path) {
        // FFmpeg直接使用で高速化
        avformat_open_input(&format_ctx_, path.c_str(), nullptr, nullptr);
        
        // メタデータをDTOとして返す
        return py::dict(
            "width"_a=codec_ctx_->width,
            "height"_a=codec_ctx_->height,
            "fps"_a=av_q2d(format_ctx_->streams[0]->avg_frame_rate),
            "frame_count"_a=format_ctx_->streams[0]->nb_frames,
            "codec"_a=codec_ctx_->codec->name
        );
    }
    
    py::dict read_frame(int index) {
        // フレームデコード
        AVFrame* frame = decode_frame_at(index);
        
        // numpy配列に変換
        py::array_t<uint8_t> data({frame->height, frame->width, 3});
        convert_to_rgb24(frame, data.mutable_data());
        
        // DTOとして返す
        return py::dict(
            "data"_a=data,
            "pts"_a=frame->pts,
            "width"_a=frame->width,
            "height"_a=frame->height,
            "frame_number"_a=index
        );
    }
};

PYBIND11_MODULE(cpp_video_reader, m) {
    py::class_<CppVideoReader>(m, "CppVideoReader")
        .def(py::init<>())
        .def("open", &CppVideoReader::open)
        .def("read_frame", &CppVideoReader::read_frame)
        .def("close", &CppVideoReader::close);
}
```

## コアデータモデル実装

### 基本データクラス

```python
from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List
import numpy as np
from enum import Enum

# 色空間定義
class ColorSpace(Enum):
    BT709 = "bt709"
    BT2020 = "bt2020"
    SRGB = "srgb"
    P3 = "p3"

# サブサンプリング定義
class ChromaSubsampling(Enum):
    YUV420 = "4:2:0"
    YUV422 = "4:2:2"
    YUV444 = "4:4:4"

@dataclass
class Frame:
    """フレームデータを保持するクラス"""
    data: np.ndarray  # HxWxC (uint8/uint16/float32)
    pts: int  # Presentation timestamp (microseconds)
    dts: Optional[int] = None  # Decoding timestamp
    timecode: str = ""  # SMPTE timecode (e.g., "01:23:45:12")
    colorspace: ColorSpace = ColorSpace.BT709
    bit_depth: int = 8  # 8, 10, 12, 16
    subsampling: ChromaSubsampling = ChromaSubsampling.YUV420
    hdr_metadata: Optional[Dict[str, Any]] = None
    field_order: Optional[str] = None  # "tff", "bff", "progressive"
    
    @property
    def frame_number(self) -> int:
        """フレーム番号を計算"""
        # FPSに基づいて計算（実装時に詳細化）
        return int(self.pts / 1000000 * 30)  # 仮に30fps
    
    def to_dict(self) -> Dict[str, Any]:
        """シリアライズ用"""
        return {
            "pts": self.pts,
            "dts": self.dts,
            "timecode": self.timecode,
            "colorspace": self.colorspace.value,
            "bit_depth": self.bit_depth,
            "subsampling": self.subsampling.value,
            "hdr_metadata": self.hdr_metadata,
            "field_order": self.field_order
        }

@dataclass
class Mask:
    """マスクデータとメタデータ"""
    data: np.ndarray  # HxW (bool or uint8)
    id: int  # オブジェクトID
    class_name: str  # クラス名（"genital"等）
    confidence: float  # 信頼度 (0.0-1.0)
    frame_index: int  # フレームインデックス
    attributes: Dict[str, Any] = field(default_factory=dict)
    
    def to_npy(self, filepath: str):
        """NPY形式で保存"""
        np.save(filepath, self.data)
    
    def to_png(self, filepath: str):
        """PNG形式で保存"""
        import cv2
        cv2.imwrite(filepath, self.data * 255)

@dataclass
class BoundingBox:
    """バウンディングボックス情報"""
    x: float  # 左上X座標
    y: float  # 左上Y座標
    width: float  # 幅
    height: float  # 高さ
    id: int  # オブジェクトID
    score: float  # 検出スコア
    class_name: str  # クラス名
    frame_index: int  # フレームインデックス
    
    @property
    def x2(self) -> float:
        return self.x + self.width
    
    @property
    def y2(self) -> float:
        return self.y + self.height
    
    def to_xyxy(self) -> tuple:
        """(x1,y1,x2,y2)形式に変換"""
        return (self.x, self.y, self.x2, self.y2)

# アラートレベル定義
class AlertLevel(Enum):
    PERFECT = "perfect"  # ほぼ完璧
    NORMAL = "normal"  # 通常再生で確認
    DETAILED = "detailed"  # 詳細確認推奨
    REQUIRED = "required"  # 修正必要

@dataclass
class AlertTag:
    """アラート情報"""
    level: AlertLevel
    reason: str
    frame_range: tuple  # (start_frame, end_frame)
    confidence: float
    metadata: Dict[str, Any] = field(default_factory=dict)
```

## Media I/O実装設計

### FFmpegラッパー基本構造

```python
import ffmpeg
import numpy as np
from typing import Iterator, Optional
import av

class MediaReader:
    """動画読み込みクラス"""
    
    def __init__(self, filepath: str):
        self.filepath = filepath
        self.container = av.open(filepath)
        self.video_stream = next(s for s in self.container.streams if s.type == 'video')
        self.audio_stream = next((s for s in self.container.streams if s.type == 'audio'), None)
        
        # メタデータ抽出
        self._extract_metadata()
    
    def _extract_metadata(self):
        """メタデータの抽出"""
        self.metadata = {
            "duration": float(self.container.duration) / av.time_base,
            "fps": float(self.video_stream.average_rate),
            "width": self.video_stream.width,
            "height": self.video_stream.height,
            "codec": self.video_stream.codec_context.name,
            "colorspace": self._detect_colorspace(),
            "bit_depth": self._detect_bit_depth(),
            "has_timecode": self._extract_timecode(),
            "is_interlaced": self._detect_interlace(),
            "field_order": self._detect_field_order()
        }
    
    def read_frames(self) -> Iterator[Frame]:
        """フレームを順次読み込み"""
        for packet in self.container.demux(self.video_stream):
            for frame in packet.decode():
                yield self._av_frame_to_frame(frame)
    
    def _av_frame_to_frame(self, av_frame) -> Frame:
        """PyAVフレームをFrameオブジェクトに変換"""
        # numpy配列に変換
        img = av_frame.to_ndarray(format='rgb24')
        
        return Frame(
            data=img,
            pts=av_frame.pts,
            dts=av_frame.dts,
            timecode=self._pts_to_timecode(av_frame.pts),
            colorspace=self._detect_colorspace(),
            bit_depth=self.metadata["bit_depth"]
        )

class MediaWriter:
    """動画書き出しクラス（ストリームコピー優先）"""
    
    def __init__(self, output_path: str, template_path: str):
        self.output_path = output_path
        self.template_path = template_path
        
        # テンプレート動画から設定をコピー
        self._setup_from_template()
    
    def write_with_stream_copy(self, input_path: str, processed_frames: List[Frame]):
        """音声ストリームコピーで書き出し"""
        # FFmpegコマンドラインを使用（ストリームコピー保証）
        input_video = ffmpeg.input(input_path)
        
        # 映像は処理済みフレームから生成
        # 音声はストリームコピー
        output = ffmpeg.output(
            processed_video_stream,
            input_video.audio,
            self.output_path,
            acodec='copy',  # 音声ストリームコピー
            **self.encoding_params
        )
        
        ffmpeg.run(output)
```

## UI基本構造

### メインウィンドウ実装

```python
from PyQt6.QtWidgets import QMainWindow, QWidget, QVBoxLayout
from PyQt6.QtCore import Qt, QSettings
import sys

class MainWindow(QMainWindow):
    """メインアプリケーションウィンドウ"""
    
    def __init__(self):
        super().__init__()
        self.settings = QSettings('MaskEditorGOD', 'MainApp')
        self.init_ui()
        self.restore_state()
    
    def init_ui(self):
        """UI初期化"""
        self.setWindowTitle("Mask Editor GOD")
        self.setMinimumSize(1280, 720)
        
        # セントラルウィジェット
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # メインレイアウト
        layout = QVBoxLayout(central_widget)
        
        # コンポーネント追加
        self._setup_menubar()
        self._setup_toolbar()
        self._setup_timeline()
        self._setup_viewer()
        self._setup_statusbar()
        
        # 日本語フォント設定
        self._setup_japanese_font()
    
    def _setup_japanese_font(self):
        """日本語フォント設定"""
        from PyQt6.QtGui import QFont, QFontDatabase
        
        # Notoフォント読み込み
        font_path = "fonts/NotoSansCJKjp-Regular.otf"
        font_id = QFontDatabase.addApplicationFont(font_path)
        
        if font_id >= 0:
            font_families = QFontDatabase.applicationFontFamilies(font_id)
            if font_families:
                font = QFont(font_families[0])
                font.setPointSize(10)
                self.setFont(font)
```

## エフェクトエンジン設計

### エフェクトインターフェース

```python
from abc import ABC, abstractmethod
from typing import Protocol, Dict, Any
import numpy as np

class IEffect(Protocol):
    """エフェクトインターフェース"""
    
    def apply(self, frame: np.ndarray, mask: np.ndarray, params: Dict[str, Any]) -> np.ndarray:
        """エフェクトを適用"""
        ...
    
    def get_default_params(self) -> Dict[str, Any]:
        """デフォルトパラメータを取得"""
        ...

class MosaicEffect:
    """モザイクエフェクト実装"""
    
    def apply(self, frame: np.ndarray, mask: np.ndarray, params: Dict[str, Any]) -> np.ndarray:
        """モザイクを適用"""
        block_size = params.get('block_size', 20)
        
        # マスク領域のみ処理
        result = frame.copy()
        h, w = frame.shape[:2]
        
        # モザイク処理（最適化の余地あり）
        for y in range(0, h, block_size):
            for x in range(0, w, block_size):
                if mask[y:y+block_size, x:x+block_size].any():
                    # ブロック内の平均色で塗りつぶし
                    block = frame[y:y+block_size, x:x+block_size]
                    avg_color = block.mean(axis=(0, 1))
                    result[y:y+block_size, x:x+block_size] = avg_color
        
        return result
    
    def get_default_params(self) -> Dict[str, Any]:
        return {
            'block_size': 20,
            'strength': 1.0
        }

class BlurEffect:
    """ブラーエフェクト実装"""
    
    def apply(self, frame: np.ndarray, mask: np.ndarray, params: Dict[str, Any]) -> np.ndarray:
        """ガウシアンブラーを適用"""
        import cv2
        
        radius = params.get('radius', 21)
        if radius % 2 == 0:
            radius += 1  # 奇数にする
        
        # マスク領域をブラー
        blurred = cv2.GaussianBlur(frame, (radius, radius), 0)
        
        # マスクでブレンド
        mask_3ch = np.repeat(mask[:, :, np.newaxis], 3, axis=2)
        result = frame * (1 - mask_3ch) + blurred * mask_3ch
        
        return result.astype(frame.dtype)
    
    def get_default_params(self) -> Dict[str, Any]:
        return {
            'radius': 21,
            'sigma': 0  # 自動計算
        }
```

## パフォーマンス最適化方針

### メモリ管理

```python
from functools import lru_cache
import gc

class FrameCache:
    """フレームキャッシュ管理"""
    
    def __init__(self, max_size: int = 100):
        self.max_size = max_size
        self._cache = {}
        self._access_order = []
    
    def get(self, frame_index: int) -> Optional[Frame]:
        """キャッシュからフレームを取得"""
        if frame_index in self._cache:
            # LRU更新
            self._access_order.remove(frame_index)
            self._access_order.append(frame_index)
            return self._cache[frame_index]
        return None
    
    def put(self, frame_index: int, frame: Frame):
        """フレームをキャッシュに追加"""
        if len(self._cache) >= self.max_size:
            # 最も古いアイテムを削除
            oldest = self._access_order.pop(0)
            del self._cache[oldest]
            gc.collect()  # 明示的なガベージコレクション
        
        self._cache[frame_index] = frame
        self._access_order.append(frame_index)

# GPUメモリ管理
class GPUMemoryManager:
    """GPU メモリ管理"""
    
    @staticmethod
    def get_available_memory() -> int:
        """利用可能なGPUメモリを取得"""
        try:
            import torch
            if torch.cuda.is_available():
                return torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()
        except:
            pass
        return 0
    
    @staticmethod
    def optimize_batch_size(frame_size: tuple, bit_depth: int) -> int:
        """最適なバッチサイズを計算"""
        available_memory = GPUMemoryManager.get_available_memory()
        frame_bytes = frame_size[0] * frame_size[1] * 3 * (bit_depth // 8)
        
        # 安全マージンを考慮（50%）
        safe_memory = available_memory * 0.5
        return max(1, int(safe_memory / frame_bytes))
```

## 品質保証実装

### 自動検証システム

```python
import hashlib
from typing import Tuple
import subprocess
import json

class QualityValidator:
    """品質検証クラス"""
    
    @staticmethod
    def verify_audio_bitperfect(input_path: str, output_path: str) -> bool:
        """音声ビットパーフェクト検証"""
        # FFmpegで音声ストリームを抽出してMD5比較
        cmd_input = [
            'ffmpeg', '-i', input_path, '-map', '0:a', '-f', 'md5', '-'
        ]
        cmd_output = [
            'ffmpeg', '-i', output_path, '-map', '0:a', '-f', 'md5', '-'
        ]
        
        input_md5 = subprocess.check_output(cmd_input).decode().strip()
        output_md5 = subprocess.check_output(cmd_output).decode().strip()
        
        return input_md5 == output_md5
    
    @staticmethod
    def calculate_delta_e00(frame1: np.ndarray, frame2: np.ndarray) -> float:
        """CIEDE2000色差計算"""
        from skimage.color import deltaE_ciede2000, rgb2lab
        
        # RGB to LAB変換
        lab1 = rgb2lab(frame1 / 255.0)
        lab2 = rgb2lab(frame2 / 255.0)
        
        # ΔE00計算
        delta_e = deltaE_ciede2000(lab1, lab2)
        return delta_e.mean()
    
    @staticmethod
    def verify_pts_accuracy(input_pts: List[int], output_pts: List[int]) -> Tuple[bool, float]:
        """PTS精度検証（±0.5ms以内）"""
        max_diff = 0
        threshold_us = 500  # 0.5ms in microseconds
        
        for i, o in zip(input_pts, output_pts):
            diff = abs(i - o)
            max_diff = max(max_diff, diff)
            
            if diff > threshold_us:
                return False, diff / 1000.0  # msに変換
        
        return True, max_diff / 1000.0

class QualityReport:
    """品質レポート生成"""
    
    def __init__(self):
        self.results = {
            "audio_bitperfect": None,
            "color_difference": [],
            "pts_accuracy": None,
            "field_order_maintained": None,
            "metadata": {}
        }
    
    def generate_report(self, output_path: str):
        """レポート生成"""
        # JSON形式
        with open(output_path + '.json', 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        # HTML形式
        self._generate_html_report(output_path + '.html')
    
    def _generate_html_report(self, output_path: str):
        """HTML形式のレポート生成"""
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>品質検証レポート</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .pass { color: green; }
                .fail { color: red; }
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background-color: #f2f2f2; }
            </style>
        </head>
        <body>
            <h1>品質検証レポート</h1>
            {content}
        </body>
        </html>
        """
        # 実装詳細は省略
```

## プロジェクトファイル構造

### .mosaicproj フォーマット

```python
import json
import zipfile
from pathlib import Path

class ProjectFile:
    """プロジェクトファイル管理"""
    
    VERSION = "1.0.0"
    
    def __init__(self):
        self.data = {
            "version": self.VERSION,
            "created_at": None,
            "modified_at": None,
            "timeline": {},
            "settings": {},
            "history": [],
            "metadata": {}
        }
    
    def save(self, filepath: str):
        """プロジェクトを保存"""
        # 一時ディレクトリに展開
        with tempfile.TemporaryDirectory() as tmpdir:
            # メインプロジェクトファイル
            project_json = Path(tmpdir) / "project.json"
            with open(project_json, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, indent=2, ensure_ascii=False)
            
            # アセット（マスク等）も含める場合
            assets_dir = Path(tmpdir) / "assets"
            assets_dir.mkdir()
            
            # ZIPファイルとして保存
            with zipfile.ZipFile(filepath, 'w', zipfile.ZIP_DEFLATED) as zf:
                for file in Path(tmpdir).rglob('*'):
                    if file.is_file():
                        arcname = file.relative_to(tmpdir)
                        zf.write(file, arcname)
    
    def load(self, filepath: str):
        """プロジェクトを読み込み"""
        with zipfile.ZipFile(filepath, 'r') as zf:
            # project.jsonを読み込み
            with zf.open('project.json') as f:
                self.data = json.load(f)
            
            # バージョンチェック
            if not self._check_version_compatibility():
                raise ValueError(f"Incompatible project version: {self.data['version']}")
```

## エラーハンドリングとロギング

### ロギングシステム

```python
import logging
from logging.handlers import RotatingFileHandler
import traceback

class Logger:
    """統一ロギングシステム"""
    
    @staticmethod
    def setup_logging(log_file: str = "mask_editor_god.log"):
        """ロギング設定"""
        # ルートロガー設定
        logger = logging.getLogger()
        logger.setLevel(logging.DEBUG)
        
        # ファイルハンドラー（ローテーション付き）
        file_handler = RotatingFileHandler(
            log_file, maxBytes=10*1024*1024, backupCount=5
        )
        file_handler.setLevel(logging.DEBUG)
        
        # コンソールハンドラー
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # フォーマッター
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
    
    @staticmethod
    def log_exception(exc: Exception, context: str = ""):
        """例外をログ"""
        logger = logging.getLogger(__name__)
        logger.error(f"Exception in {context}: {str(exc)}")
        logger.error(traceback.format_exc())

# エラーハンドリングデコレータ
def handle_errors(context: str = ""):
    """エラーハンドリングデコレータ"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                Logger.log_exception(e, context or func.__name__)
                # UIに通知（実装による）
                raise
        return wrapper
    return decorator
```

## テスト戦略

### ユニットテスト例

```python
import pytest
import numpy as np

class TestFrame:
    """Frameクラスのテスト"""
    
    def test_frame_creation(self):
        """フレーム作成テスト"""
        data = np.zeros((1080, 1920, 3), dtype=np.uint8)
        frame = Frame(
            data=data,
            pts=1000000,
            timecode="00:00:01:00"
        )
        
        assert frame.pts == 1000000
        assert frame.timecode == "00:00:01:00"
        assert frame.colorspace == ColorSpace.BT709
    
    def test_frame_serialization(self):
        """シリアライズテスト"""
        frame = Frame(
            data=np.zeros((100, 100, 3)),
            pts=2000000
        )
        
        data = frame.to_dict()
        assert data["pts"] == 2000000
        assert "colorspace" in data

class TestQualityValidator:
    """品質検証のテスト"""
    
    def test_delta_e00_calculation(self):
        """色差計算テスト"""
        frame1 = np.ones((100, 100, 3), dtype=np.uint8) * 128
        frame2 = np.ones((100, 100, 3), dtype=np.uint8) * 129
        
        delta_e = QualityValidator.calculate_delta_e00(frame1, frame2)
        assert delta_e < 1.0  # ΔE00 ≤ 1.0
    
    @pytest.mark.parametrize("pts_diff,expected", [
        (100, True),   # 0.1ms - OK
        (500, True),   # 0.5ms - OK
        (600, False),  # 0.6ms - NG
    ])
    def test_pts_accuracy(self, pts_diff, expected):
        """PTS精度テスト"""
        input_pts = [1000000, 2000000, 3000000]
        output_pts = [p + pts_diff for p in input_pts]
        
        result, max_diff = QualityValidator.verify_pts_accuracy(input_pts, output_pts)
        assert result == expected
```

### ディレクトリ構造
```
mask_editor_god/
├── src/
│   ├── core/              # コアロジック
│   │   ├── __init__.py
│   │   ├── models.py      # データモデル
│   │   ├── media_io.py    # Media I/O
│   │   └── effects.py     # エフェクト
│   ├── ui/                # UIコンポーネント
│   │   ├── __init__.py
│   │   ├── main_window.py
│   │   └── widgets/
│   ├── services/          # ドメインサービス
│   │   ├── __init__.py
│   │   ├── mask_editor.py
│   │   └── quality_validator.py
│   └── utils/             # ユーティリティ
│       ├── __init__.py
│       └── logger.py
├── tests/                 # テスト
├── docs/                  # ドキュメント
├── resources/             # リソース
│   └── fonts/
├── requirements.txt
├── pyproject.toml
└── README.md
```


### 入力データアダプターの実装
```python
# 抽象インターフェース
class IInputDataSource(Protocol):
    def get_video_path(self) -> Path: ...
    def get_detections(self, frame_index: int) -> List[DetectionDTO]: ...
    def get_mask(self, frame_index: int) -> Optional[MaskDTO]: ...

# 具体的な実装（ローカルファイル用）
class LocalFileInputAdapter:
    def __init__(self, base_path: Path):
        self.base_path = base_path
        # 実装...

# 将来的な実装（ネットワーク用）
class NetworkInputAdapter:
    def __init__(self, api_endpoint: str):
        self.api_endpoint = api_endpoint
        # 実装...
```
