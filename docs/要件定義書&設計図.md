# ソフトウェア要件定義書

## 1. 目的・背景

本ソフトウェアは、動画内の性器領域に対し、AI が自動生成したマスクを元にモザイク／ブラー等のエフェクトを適用し、必要に応じて人手で微修正できる動画編集支援ツールである。本要件定義書は、当該ツールの機能要件・非機能要件を明確化し、関係者間の共通認識を形成することを目的とする。

※ 音声編集は行わない前提であり、音声は基本ストリームコピー（再エンコード禁止）とする。

---

## 2. 用語定義・略語

- **マスク**：フレームごとの対象領域を示す2値または多値画像（NPY/PNG 等）。
- **ID**：同一対象を時系列に追跡するための識別子。
- **シーン**：ショット境界検出等で分割された動画の意味的／編集的区間。
- **オプティカルフロー（OF）**：隣接フレーム間の画素移動ベクトル。
- **閾値（Threshold）**：検出・IDマージ・シーン切替等の判断基準。
- **ストリームコピー（Remux/Passthrough）**：コーデック再圧縮を行わず、コンテナの再多重化のみを行う処理。
- **ビットパーフェクト（Bit-Perfect）**：入力PCM音声データと出力PCM音声データのサンプル値が完全一致（±1 LSB以内）している状態。
- **ΔE00**：CIEDE2000 色差指標。ΔE00 ≤ 1.0 を事実上「目視不可差」とする。
- **タイムコード（TC）**：映像・音声の時間管理用カウンタ（Drop Frame / Non Drop Frame）。
- **VFR (Variable Frame Rate)**：各フレームの表示時間が可変の動画。
    
    **CFR (Constant Frame Rate)**：全フレームが一定間隔で配置された動画。
    
- **インターレース**：フィールド（偶数／奇数ライン）で構成される映像方式。TFF（Top Field First）/BFF（Bottom Field First）。

---

## 3. 前提・制約

- **前提**：AI により生成された初期マスクが一定精度で提供される。
- **処理形態**：デフォルトはローカル環境でのオフライン処理。クラウド送信はユーザー明示許可必須。
- **対応OS**：Windows 10 以降／macOS 12 以降／Ubuntu 22.04 以降。
- **ハードウェア**：GPU（CUDA / Metal / Vulkan 他）によるアクセラレーションを前提。

---

## 4. 入力・出力データ要件

### 4.1 入力データ（Input）

| ID | データ種別 | 形式 | 説明 |
| --- | --- | --- | --- |
| IN-1 | 元動画 | MP4(H.264/H.265), MOV, AVI, 他主要コーデック | 可能な限り多コーデックをサポート（FFmpeg 等利用）。 |
| IN-2 | マスクデータ | NPY(H×W×C), PNG | AI生成済み。1bit/8bit対応。 |
| IN-3 | マスク属性情報 | JSON | ID, クラス, 信頼度, 対応フレーム等。 |
| IN-4 | バウンディングボックス | JSON | x, y, w, h, ID, スコア等。 |
| IN-5 | オプティカルフロー | NPY/NPZ | フレーム間Flow（2ch or 3ch）。 |
| IN-6 | メタデータ | JSON | シーン分類、アラート情報など。 |

### 4.2 出力データ（Output）

- 処理済み動画（例：MP4/H.264 + AAC）
- 更新後マスク（NPY/PNG）
- 編集プロジェクトファイル（`.mosaicproj`：JSON/ZIP）
- 統計レポート（CSV/HTML）
- 学習用差分データ（COCO形式JSON 等）

---

## 5. 機能要件

### 5.1 入出力・プロジェクト管理

- **FR-1（MUST）** マルチフォーマット入出力：MP4(H.264/H.265), MOV, AVI 他主要コーデック対応。
- **FR-2（MUST）** プロジェクト保存：タイムライン、編集履歴、設定を一括保存（拡張子 `.mosaicproj`）。
- **FR-3（SHOULD）** オートセーブ＆バージョン管理：任意間隔で自動保存、過去バージョン復元。

### 5.2 UI 基盤

- **FR-4（MUST）** タイムライン & スクラブ：フレーム／秒単位ズーム、ドラッグでプレビュー同期。
- **FR-5（SHOULD）** 未処理/未確認可視化：タイムライン上で状態を色分け表示。
- **FR-6（MUST）** アラート表示：アラート機能（FR-19〜）をタイムラインに重畳表示。
- **FR-7（SHOULD）** 再生・コマ送り：任意FPS/速度。確認用と閲覧用モードを区別。
- **FR-8（MUST）** レイヤースタック：原動画／マスク／エフェクト設定を独立管理、表示ON/OFF。
- **FR-9（SHOULD）** マルチビュー：①元動画 ②マスクオーバーレイ ③処理結果の3ペイン表示。

### 5.3 マスク編集

- **FR-10（MUST）** モルフォロジー操作：膨張／収縮／オープン／クローズのGUI制御。
- **FR-11（MUST）** ブラシ編集：新規ID追加モード／既存ID加筆モード切替。
- **FR-12（MUST）** トラッキング補完：手動で描いたマスクをフレーム間補間（線形／OF）。
- **FR-13（MUST）** マスク削除：誤検出IDや範囲指定削除。
- **FR-14（SHOULD）** 閾値調節UI：性器検出閾値・IDマージ閾値をスライダー調整。

### 5.4 エフェクト処理

- **FR-15（MUST）** モザイク／ブラー／ピクセレート：ブロックサイズ・強度・半径など可変。
- **FR-16（SHOULD）** キーフレーム：エフェクトパラメータを時間軸で補間・アニメーション化。

### 5.5 一括適用 & スコープ管理

- **FR-17（MUST）** 適用スコープ選択：フレーム／ID／シーン／全体で一括操作。
- **FR-18（MUST）** ID・シーン切替閾値：閾値小＝ID細分化／閾値大＝ID集約を動的切替。

### 5.6 アラート機能

- **FR-19（MUST）** AI出力グルーピング：「ほぼ完璧／通常再生で確認／詳細確認推奨／修正必要」を自動タグ付け。
- **FR-20（SHOULD）** 危険物検出アラート：水面・鏡・反射面等、誤検出／漏れが多い領域を検知・表示。
- **FR-21（MAY）** シーン分類：NLPでシーン内容をタグ分類し、確認優先度を提案。

### 5.7 学習・解析機能（同意制御）

- **FR-22（SHOULD）** ネガティブサンプリング収集：削除されたマスクを誤検出としてログ化。
- **FR-23（SHOULD）** ポジティブサンプリング収集：追加・加筆されたマスクを検出漏れとして保存。
- **FR-24（SHOULD）** 統計レポート：工数、修正内容、漏れ率、ID切替回数等の出力（CSV/HTML）。
- **FR-25（MAY）** 再学習パイプライン出力：COCO／YOLO等フォーマットで差分エクスポート。

### 5.8 出力・連携

- **FR-26（MUST）** 非破壊レンダリング：元動画保持、エフェクト適用結果を別出力。低解像度プレビュー→高解像度最終出力。
- **FR-27（MAY）** プラグインSDK：Python/C++でエフェクト追加可能。

### 5.9 **NLE品質維持系 機能要件（音声／色彩／タイムコード／コーデック）**

> NLEでは当たり前のクオリティをここに集約。音声編集なし前提。
> 

### 音声（編集なし）

- **FR-28（MUST）** 入力音声は再エンコードせずストリームコピー可能（PCM/AAC/AC-3/FLAC/Opus/MP3等主要フォーマット）。
- **FR-29（MUST）** 音声と映像の同期誤差を ±20 ms（≒1フレーム）以内に保持。同期調整の自動／手動補正機能を提供。
- **FR-30（SHOULD）** サンプルレート／チャンネルレイアウト／言語タグなどメタデータを保持。

### カラーマネジメント／色彩保持

- **FR-31（MUST）** 入力素材の色空間（BT.709/BT.2020 等）、トランスファ特性（gamma/HLG/PQ 等）、ビット深度（8/10/12bit）、サブサンプリング（4:2:0/4:2:2/4:4:4）を自動認識し保持。
- **FR-32（MUST）** ストリームコピー時はピクセル値変化ゼロ（変換禁止）。変換が必要な場合のみ、ユーザーが選択した LUT / ICC / ACES トランスフォームを適用。
- **FR-33（SHOULD）** HDRメタデータ（MaxCLL/MaxFALL 等）保持、SDR変換時はトーンマッピング方式（例：HLG→BT.709）を選択可能。

### タイムコード／フレームレート／VFR

- **FR-34（MUST）** 入力TC（DF/NDF）と各フレームの PTS/DTS を保持し、正確なシーク・編集を可能にする。
- **FR-35（MUST）** 出力時に VFR 維持／指定CFR変換を選択可。CFR化時は「フレーム複製／間引き／タイムリマップ方式」を提示。
- **FR-36（MUST）** タイムコード（開始値、リール名等）をプロジェクトファイルと出力ファイル双方に保存。

### インターレース

- **FR-37（MUST）** フィールドオーダー（TFF/BFF）検出・保持。
- **FR-38（MUST）** 出力時オプション：インターレース維持／デインターレース／再インターレース。方式の選択肢を提供。

### コーデック／コンテナ

- **FR-39（MUST）** 入力対応：H.264/AVC, H.265/HEVC, ProRes, DNxHR, AV1, MPEG-2, VP9, HAP 等主要NLEが扱うコーデック／MP4/MOV/MXF/MKV 等コンテナ。
- **FR-40（MUST）** 出力対応：同上主要コーデックを選択可。ストリームコピーを最優先とする。
- **FR-41（SHOULD）** 色深度やサブサンプリングを保持するプロファイルを提供しユーザー選択を可能に。
- **FR-42（MAY）** マイナー／プロプライエタリコーデック（例：EDIUS系 HQ/HQX 等）への対応は拡張手段で検討。

---

## 6. 非機能要件

### 6.1 性能

- **NFR-1（MUST）** 1080p@30fps プレビューで ≦ 50 ms／frame（平均）。
- **NFR-2（SHOULD）** GPUアクセラレーション（CUDA/Metal/Vulkan/OpenCL）による主要処理の高速化。
- **NFR-3（SHOULD）** 4K@30fps プレビュー対応を想定した設計。

### 6.2 スケーラビリティ & 拡張性

- **NFR-4（MUST）** 4K まで拡張可能。
- **NFR-5（SHOULD）** 将来VR（360°動画）対応を想定しモジュール化。
- **NFR-6（SHOULD）** UI／Core／I/O／ML コンポーネントを分離したモジュール化アーキテクチャ。

### 6.3 信頼性・可用性

- **NFR-7（MUST）** オートセーブ間隔デフォルト1分。クラッシュ後リカバリ機能。
- **NFR-8（SHOULD）** 操作ログ・監査ログをローカル保存（JSONL）。
- **NFR-9（MAY）** E2E／ユニットテストカバレッジ 80% 以上を目標。

### 6.4 セキュリティ / プライバシ

- **NFR-10（MUST）** サーバ接続はユーザー明示操作のみ。無断送信禁止。
- **NFR-11（MUST）** クラウド送信時は AES-256 で暗号化、期限付き署名URL等を使用。

### 6.5 ユーザビリティ / アクセシビリティ

- **NFR-12（MUST）** 主要操作にキーボードショートカット。Undo/Redo 100 ステップ以上。

### 6.6 互換性（Compatibility）

- **NFR-13（MUST）** Windows 10+, macOS 12+, Ubuntu 22.04+ で動作。
- **NFR-14（MUST）** Commercial NLE I/O Parity：NLEが提供する入出力形態・色再現性・ビット深度・クロマサブサンプリング保持ポリシーと同等のクオリティ／同一性を保証。
- **NFR-15（MAY）** Minor/Proprietary Codec Support（EDIUS 等）：マイナー／プロプライエタリコーデックの入出力・再符号化に対応。

### 6.7 ローカリゼーション（L10N/I18N）

- **NFR-16（MUST）** 日本語UIを既定。英語・中国語等への容易な切替（i18nフレームワーク導入）。

### 6.8 保守性（Maintainability）

- **NFR-17（SHOULD）** コード規約（PEP8/Black 等）と静的解析、CI/CD 導入。
- **NFR-18（MAY）** プラグイン API のバージョン管理と後方互換ポリシー定義。

### 6.9 **NLE品質維持系 非機能要件（品質基準・ログ）**

### 品質基準

- **NFR-19（MUST）** 音声ビットパーフェクト：可逆音声はPCM値一致（±1 LSB以内）。ロッシー音声は再エンコード禁止でバイナリ一致。
- **NFR-20（MUST）** 色差：ストリームコピー時は差分0。変換時 ΔE00 ≤ 1.0、または Y/Cb/Cr 各8bit値で ±1 以内。
- **NFR-21（MUST）** PTS 誤差 ±0.5 ms、CFR→CFR変換時は FPS 変更禁止（明示指定時のみ変更）。
- **NFR-22（MUST）** インターレース維持時にフィールドオーダーが変化しない（TFF→TFF／BFF→BFF）。
- **NFR-23（SHOULD）** 自動検証スクリプト（例：FFmpeg/FFprobe + 差分比較ツール）で品質チェック可能。

### ログ／トレーサビリティ

- **NFR-24（MUST）** 変換パイプライン（色空間変換・タイムリマップ等）と設定値をログ化。
- **NFR-25（SHOULD）** 入出力ハッシュや誤差指標を JSON で保存し、後から品質再検証可能に。

---

## 7. 受入れ基準（サンプル）

| 要件ID | 試験項目 | 入力条件 | 期待結果 | 判定方法 |
| --- | --- | --- | --- | --- |
| FR-28 / NFR-19 | PCM音声ストリームコピー | 48kHz/24bit PCM、編集なし | 入力と出力PCMのMD5一致 | 自動ハッシュ比較スクリプト |
| FR-32 / NFR-20 | ピクセル値差分（コピー時） | 10bit 4:2:2 ProRes（BT.709） | 差分0（ΔE00=0） | 画素比較ツール（ffmpeg + numpy） |
| FR-35 / NFR-21 | VFR保持 | 23.976–24.000混在素材 | PTS誤差 ±0.5ms 以内 | FFprobeでPTS差分解析 |
| FR-37 / NFR-22 | フィールドオーダー維持 | 1080i60 TFF 素材 | オーダー不変 | Mediainfo/FFprobeでオーダー確認 |
| FR-39 | 多コーデック入力再生 | H.264/HEVC/ProRes/DNxHR | すべて正常デコード・サムネ生成 | 自動デコードテスト |

※ 実際の試験項目はテスト計画書で詳細化する。

---

## 8. ログ・監査・可観測性

- 処理ログ：モジュール別（I/O、色変換、タイムライン編集など）にINFO/DEBUG/ERRORを出力。
- 品質ログ：入出力ハッシュ、ΔE00、PTS誤差、同期調整量などを JSONL で保存。
- 可視化：処理時間分布、GPU/VRAM消費などをダッシュボード化（SHOULD）。

---

## ９. 設計思想（前提の再確認）

- **ローカル・オフライン処理がデフォルト**。クラウド送信は明示許可必須。
- **マルチコーデック入出力 & .mosaicproj 保存はMUST**。
- **非破壊レンダリング／ストリームコピー優先／ピクセル差分ゼロ／音声ビットパーフェクト**などNLE同等品質を保証。
- **UI/Core/I/O/ML のモジュール分離を非機能要件で要求**。
- **1080p@30fpsで≤50ms/frameのプレビュー性能**。

---

## 10. レイヤ & コンポーネント分割案

```
[Presentation Layer / UI]
  ├─ Timeline/Viewer/Mask Editor GUI
  ├─ Alert Overlay, Color-coded Status
  └─ Shortcut/Undo/Redo Handler
        ↑  (Qt/QML or PySide, Python中心)

[Application Core (Orchestrator)]
  ├─ Project Manager (.mosaicproj I/O)
  ├─ Job/Task Scheduler & Pipeline Builder
  ├─ State/History (Undo/Redo) Manager
  ├─ Plugin Manager (Python-first API)
  └─ Logging/Telemetry Collector

[Domain Services]
  ├─ Media I/O Service (Decode/Encode/Remux)
  ├─ Mask/ID/Scene Service (Edit, Merge, Threshold)
  ├─ Alert Service (FR19 etc.)
  ├─ FX Engine (Mosaic/Blur etc.)
  ├─ QC/Validation Service (ΔE00, PTS差, Hash)
  └─ Learning Data Exporter (COCO/YOLO diff)

[ML/Inference Subsystem]
  ├─ Detector/Segmentor Wrapper (PyTorch/ONNX)
  ├─ OF/Tracking Module
  └─ Confidence/Thresholding

[Infrastructure Layer]
  ├─ FFmpeg Binding, GPU Kernels
  ├─ Memory Pool / Zero-copy Buffers
  └─ IPC/RPC (optional for future scaling)

```

- **C++化優先候補**：Media I/O、FX Engine、OF/Tracking、巨大マスク形態学処理。
- **Pythonで残すと良い層**：UI、Orchestrator、Logging/Telemetry、Plugin API。

---

## 11. 境界設計（Boundary Design）

### 11.1 境界の切り方

- **APIは最初から抽象インターフェース**（Python Protocol/ABC）で定義し、実装は差し替え可能にする。
- **データ構造はシリアライズ前提の純粋構造体**（numpy / dataclass / pydantic）で固定。
- **Compute-heavy関数は “pure function” 形に**：`out = fx(frame, mask, params)` のように副作用なし。
- **ゼロコピー転送を意識**：DLPack / CUDA Array Interface / Arrow などを利用。

### 11.2 C++ブリッジ方針

- **pybind11 + CMake** を基本ルート。`py::gil_scoped_release`でGILを外して高速化。
- C++側は**C API or Stable ABI**を用意→Python側は薄いバインディング。
- 置換時は**同じ関数シグネチャ**を満たす新モジュールをロードするだけでOKな構造に。

---

## 12. データ設計（Data Design）

### 12.1 コアデータモデル（要件準拠）

| Entity | 必須フィールド例 | 備考 |
| --- | --- | --- |
| **Frame** | `ndarray/ptr`, `pts:int64`, `tc:str`, `colorspace:str`, `bit_depth:int` | PTS/DTS & TC保持はMUST。 |
| **Mask** | `ndarray(bool/uint8)`, `id:int`, `class:str`, `conf:float` | NPY/PNG / 1bit or 8bit。 |
| **BBox** | `x,y,w,h, id, score` | JSON 仕様。 |
| **OF** | `flow: HxWx2 float32` | NPY/NPZ。 |
| **AlertTag** | `level:enum(4段階)`, `reason`, `range` | FR19。 |
| **Project** | timeline, edits, settings, TC map | 拡張子 .mosaicproj(JSON/ZIP)。 |

### 型定義サンプル（Python）

```python
python
コピーする編集する
@dataclass
class Frame:
    data: np.ndarray  # HxWxC uint8/float32
    pts: int
    dts: int | None
    timecode: str
    colorspace: str
    bit_depth: int
    subsampling: str  # "4:2:0", etc.

@dataclass
class MaskMeta:
    id: int
    cls: str
    conf: float
    frame_index: int

```

### 12.2 品質/ログデータ

- **品質ログ**：ΔE00, PTS誤差, 入出力ハッシュ等を JSONL で保存。
- **受け入れ基準**に合わせた値（ΔE00≤1.0, PTS ≤0.5ms 等）を自動計算。

---

## 13. 全体設計図（High-level Architecture）

```

+---------------------------------------------------------------+
|                           UI Layer                            |
|  Qt/QML Widgets, Timeline, Mask Editor, Alert Overlay         |
+------------------------↑--------------------------------------+
                         | Commands/Events
+------------------------|--------------------------------------+
|                   Application Core (Python)                   |
|  ProjectMgr  TaskScheduler  Undo/Redo  PluginMgr  Logger      |
+-----------↑---------------↑---------------↑-------------------+
            |               |               |
    +-------|-------+ +-----|------+ +------|------------------+
    | Media I/O Svc | |  AI Engine | | FX/Render Engine        |
    | (FFmpeg)      | | (Torch/ONNX)| | (OpenCV/Numpy→C++/CUDA) |
    +-------↑-------+ +-----↑------+ +------↑------------------+
            |             |                |
    +-------|-------------|----------------|-------------------+
    |            QC/Validation & Alert Service                 |
    +----------------------------------------------------------+
    |                Logging/Telemetry Storage                 |
    +----------------------------------------------------------+

```

---

## 13-A. Hexagonal Architecture（Port/Adapter）設計

### 13-A.1 アーキテクチャ概要

本プロジェクトは、ビジネスロジックを外部技術から独立させ、コンポーネントの置換を容易にするため、Hexagonal Architecture（Port/Adapter パターン）を採用する。

```
┌─────────────────────────────────────────────────────────────┐
│                     Primary Adapters                        │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐         │
│  │ PyQt UI │ │ Web API │ │   CLI   │ │Test Mock│         │
│  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘         │
│       │           │           │           │                │
│  ┌────┴───────────┴───────────┴───────────┴────┐          │
│  │            Primary Ports (Interfaces)        │          │
│  │  IProjectService, IVideoEditor, IEffectEngine│          │
│  └────────────────────┬─────────────────────────┘          │
│                       │                                     │
│  ┌────────────────────┴─────────────────────────┐          │
│  │            Application Core                  │          │
│  │        (Pure Business Logic)                │          │
│  │   - Project Management                      │          │
│  │   - Mask Editing Logic                      │          │
│  │   - Effect Calculation                      │          │
│  │   - Alert Rules                             │          │
│  └────────────────────┬─────────────────────────┘          │
│                       │                                     │
│  ┌────────────────────┴─────────────────────────┐          │
│  │         Secondary Ports (Interfaces)         │          │
│  │  IVideoReader, IMaskStorage, IEffectRenderer│          │
│  └────┬───────────┬───────────┬───────────┬────┘          │
│       │           │           │           │                │
│  ┌────┴────┐ ┌────┴────┐ ┌────┴────┐ ┌────┴────┐         │
│  │PyAV     │ │FFmpeg   │ │OpenCV   │ │CUDA     │         │
│  │Adapter  │ │C++ Adpt │ │Adapter  │ │Adapter  │         │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘         │
│                   Secondary Adapters                        │
└─────────────────────────────────────────────────────────────┘
```

### 13-A.2 Port（インターフェース）定義

#### Primary Ports（アプリケーションへの入力）
```python
# src/domain/ports/primary/project_service.py
from typing import Protocol
from ...dto import ProjectDTO, VideoFileDTO

class IProjectService(Protocol):
    """プロジェクト管理のためのポート"""
    def create_project(self, name: str) -> ProjectDTO: ...
    def open_project(self, path: str) -> ProjectDTO: ...
    def save_project(self, project: ProjectDTO) -> None: ...
    def import_video(self, video: VideoFileDTO) -> None: ...
```

#### Secondary Ports（外部リソースへのアクセス）
```python
# src/domain/ports/secondary/video_reader.py
from typing import Protocol, Iterator
from ...dto import FrameDTO, VideoMetadataDTO

class IVideoReader(Protocol):
    """ビデオ読み込みのためのポート"""
    def open(self, path: str) -> VideoMetadataDTO: ...
    def read_frame(self, index: int) -> FrameDTO: ...
    def read_frames(self, start: int, end: int) -> Iterator[FrameDTO]: ...
    def close(self) -> None: ...
```

### 13-A.3 DTO/VO（Data Transfer Object / Value Object）

外部ライブラリ固有の型（PyAVのVideoFrame、QPixmap等）をドメイン境界で純粋なデータ型に変換する。

```python
# src/domain/dto/frame_dto.py
from dataclasses import dataclass
import numpy as np

@dataclass(frozen=True)
class FrameDTO:
    """フレームデータ転送オブジェクト"""
    data: np.ndarray  # 常にRGB24形式
    pts: int          # マイクロ秒単位
    width: int
    height: int
    frame_number: int

# src/domain/dto/mask_dto.py
@dataclass(frozen=True)
class MaskDTO:
    """マスクデータ転送オブジェクト"""
    data: np.ndarray  # 常に0-255のuint8
    object_id: int
    confidence: float
    class_name: str
```

### 13-A.4 Adapter実装例

```python
# src/adapters/secondary/pyav_video_reader.py
import av
from ...domain.ports.secondary import IVideoReader
from ...domain.dto import FrameDTO, VideoMetadataDTO

class PyAVVideoReader:
    """PyAVを使用したビデオリーダーアダプター"""
    
    def __init__(self):
        self._container = None
        self._video_stream = None
    
    def open(self, path: str) -> VideoMetadataDTO:
        self._container = av.open(path)
        self._video_stream = self._container.streams.video[0]
        
        # PyAV固有の型をDTOに変換
        return VideoMetadataDTO(
            width=self._video_stream.width,
            height=self._video_stream.height,
            fps=float(self._video_stream.average_rate),
            frame_count=self._video_stream.frames,
            codec=self._video_stream.codec.name
        )
    
    def read_frame(self, index: int) -> FrameDTO:
        # PyAVのVideoFrameをDTOに変換
        self._container.seek(index)
        for frame in self._container.decode(video=0):
            return FrameDTO(
                data=frame.to_ndarray(format='rgb24'),
                pts=frame.pts,
                width=frame.width,
                height=frame.height,
                frame_number=index
            )
```

### 13-A.5 DIコンテナ設定

```python
# src/infrastructure/di_container.py
from typing import Dict, Type, Callable, Any

class DIContainer:
    """依存性注入コンテナ"""
    
    def __init__(self):
        self._factories: Dict[Type, Callable[[], Any]] = {}
        self._instances: Dict[Type, Any] = {}
        self._config: Dict[str, Any] = {}
    
    def register(self, interface: Type, factory: Callable, singleton: bool = False):
        """インターフェースに対するファクトリーを登録"""
        self._factories[interface] = (factory, singleton)
    
    def resolve(self, interface: Type) -> Any:
        """インターフェースの実装を解決"""
        if interface in self._instances:
            return self._instances[interface]
        
        if interface not in self._factories:
            raise ValueError(f"No factory registered for {interface}")
        
        factory, singleton = self._factories[interface]
        instance = factory(self)
        
        if singleton:
            self._instances[interface] = instance
        
        return instance
    
    def configure(self, config: Dict[str, Any]):
        """設定を更新"""
        self._config.update(config)

# src/infrastructure/container_config.py
def configure_container(container: DIContainer, config: Dict[str, Any]):
    """コンテナの設定"""
    container.configure(config)
    
    # Video Reader の登録
    if config.get('video_reader.backend') == 'cpp':
        container.register(
            IVideoReader,
            lambda c: CppVideoReader(),
            singleton=False
        )
    else:
        container.register(
            IVideoReader,
            lambda c: PyAVVideoReader(),
            singleton=False
        )
    
    # Effect Engine の登録
    if config.get('effect_engine.backend') == 'cpp':
        container.register(
            IEffectEngine,
            lambda c: CppEffectEngine(use_gpu=config.get('effect_engine.use_gpu', False)),
            singleton=True
        )
    else:
        container.register(
            IEffectEngine,
            lambda c: PythonEffectEngine(),
            singleton=True
        )
```

---

## 14. 詳細設計図（Subsystem別）

### 14.1 Media I/O Service

- **責務**：多コーデック入出力、ストリームコピー、TC/PTS保持、インターレース/フィールドオーダ対応。
    - FR39,40 入出力対応。
    - PTS/DTS保持、VFR維持/CFR変換。
    - フィールドオーダー維持。
- **実装**：初期は PyAV/ffmpeg-python。高速化時に libav* を C++ 直叩き。
- **API例**：`read_frames(path) -> Iterator[Frame]`, `write_stream(frames, audio_copy=True, ...)`.

### 14.2 Mask/ID/Scene Service

- **責務**：モルフォロジー処理、ブラシ編集、フレーム間補間、閾値UI連携、ID統合/分割。
    - FR10,11,12,13,14。
    - FR17 ID/シーン切替閾値動的切替。
- **C++化ポイント**：大規模マスクへの形態学演算、OpticalFlowベース補間。

### 14.3 FX/Render Engine

- **責務**：モザイク/ブラー/ピクセレート、キーフレーム補間（FR16）。
- **要件**：非破壊レンダリング（低解像度プレビュー→高解像度最終）。
- **C++化ポイント**：SIMD/GPU最適化、バッチ処理、ゼロコピー。

### 14.4 Alert Service

- **責務**：AI出力の4段階タグ付け、危険物検出アラート。
    - FR19,20。
- **実装**：統計的閾値＋ルールベース（反射/鏡検出）。

### 14.5 QC/Validation Service

- **責務**：ΔE00 計測、PTS誤差、インターレース維持、音声MD5等を自動チェック。
    - NFR20/21、受入基準に準拠。
- **実装**：ffmpeg + numpy / OpenColorIO / custom metrics。

### 14.6 Learning Data Exporter

- **責務**：ネガ/ポジサンプル収集、工数レポート、COCO/YOLO差分エクスポート。
    - FR22〜25。

---

## 15. Python⇔C++ 切替のための共通API例

### 15.1 共通インターフェース定義

```python
# src/domain/ports/secondary/effect_engine.py
from typing import Protocol, List
from ..dto import FrameDTO, MaskDTO, EffectParamsDTO

class IEffect(Protocol):
    """エフェクトの共通インターフェース"""
    def apply(self, frame: FrameDTO, mask: MaskDTO, params: EffectParamsDTO) -> FrameDTO: ...
    def apply_batch(self, frames: List[FrameDTO], masks: List[MaskDTO], params: EffectParamsDTO) -> List[FrameDTO]: ...
```

### 15.2 Python実装

```python
# src/adapters/secondary/python_blur_effect.py
import cv2
import numpy as np
from ...domain.ports.secondary import IEffect
from ...domain.dto import FrameDTO, MaskDTO, EffectParamsDTO

class PythonBlurEffect:
    """Python/OpenCVによるブラーエフェクト実装"""
    
    def apply(self, frame: FrameDTO, mask: MaskDTO, params: EffectParamsDTO) -> FrameDTO:
        # マスク領域にブラーを適用
        kernel_size = params.get('kernel_size', 21)
        blurred = cv2.GaussianBlur(frame.data, (kernel_size, kernel_size), 0)
        
        # マスクを使って合成
        mask_3ch = np.stack([mask.data] * 3, axis=-1) / 255.0
        result = frame.data * (1 - mask_3ch) + blurred * mask_3ch
        
        return FrameDTO(
            data=result.astype(np.uint8),
            pts=frame.pts,
            width=frame.width,
            height=frame.height,
            frame_number=frame.frame_number
        )
    
    def apply_batch(self, frames: List[FrameDTO], masks: List[MaskDTO], params: EffectParamsDTO) -> List[FrameDTO]:
        # シンプルな実装：各フレームに順次適用
        return [self.apply(f, m, params) for f, m in zip(frames, masks)]
```

### 15.3 C++実装（pybind11）

```cpp
// src/cpp_extensions/effects/blur_effect.cpp
#include <pybind11/pybind11.h>
#include <pybind11/numpy.h>
#include <pybind11/stl.h>
#include <opencv2/opencv.hpp>
#include <tbb/parallel_for.h>

namespace py = pybind11;

class CppBlurEffect {
public:
    py::dict apply(py::dict frame_dto, py::dict mask_dto, py::dict params) {
        // DTOからデータを抽出
        auto frame_data = frame_dto["data"].cast<py::array_t<uint8_t>>();
        auto mask_data = mask_dto["data"].cast<py::array_t<uint8_t>>();
        int kernel_size = params.contains("kernel_size") ? 
            params["kernel_size"].cast<int>() : 21;
        
        // OpenCV Matに変換
        cv::Mat frame(frame_data.shape(0), frame_data.shape(1), CV_8UC3, 
                     (uint8_t*)frame_data.data());
        cv::Mat mask(mask_data.shape(0), mask_data.shape(1), CV_8U,
                    (uint8_t*)mask_data.data());
        
        // ブラー処理（SIMD最適化）
        cv::Mat blurred;
        cv::GaussianBlur(frame, blurred, cv::Size(kernel_size, kernel_size), 0);
        
        // マスク合成（並列化）
        cv::Mat result;
        frame.copyTo(result);
        
        tbb::parallel_for(0, frame.rows, [&](int y) {
            for (int x = 0; x < frame.cols; ++x) {
                float alpha = mask.at<uint8_t>(y, x) / 255.0f;
                if (alpha > 0) {
                    cv::Vec3b& pixel = result.at<cv::Vec3b>(y, x);
                    cv::Vec3b blurred_pixel = blurred.at<cv::Vec3b>(y, x);
                    for (int c = 0; c < 3; ++c) {
                        pixel[c] = pixel[c] * (1 - alpha) + blurred_pixel[c] * alpha;
                    }
                }
            }
        });
        
        // 結果をDTOとして返す
        py::array_t<uint8_t> result_array({result.rows, result.cols, 3});
        std::memcpy(result_array.mutable_data(), result.data, result.total() * result.elemSize());
        
        return py::dict(
            "data"_a=result_array,
            "pts"_a=frame_dto["pts"],
            "width"_a=frame_dto["width"],
            "height"_a=frame_dto["height"],
            "frame_number"_a=frame_dto["frame_number"]
        );
    }
    
    py::list apply_batch(py::list frames, py::list masks, py::dict params) {
        py::list results;
        
        // バッチ処理の並列化
        #pragma omp parallel for
        for (size_t i = 0; i < frames.size(); ++i) {
            auto result = apply(frames[i], masks[i], params);
            #pragma omp critical
            results.append(result);
        }
        
        return results;
    }
};

PYBIND11_MODULE(cpp_blur_effect, m) {
    py::class_<CppBlurEffect>(m, "CppBlurEffect")
        .def(py::init<>())
        .def("apply", &CppBlurEffect::apply,
             "Apply blur effect to a single frame",
             py::arg("frame"), py::arg("mask"), py::arg("params"))
        .def("apply_batch", &CppBlurEffect::apply_batch,
             "Apply blur effect to multiple frames in parallel",
             py::arg("frames"), py::arg("masks"), py::arg("params"));
}
```

### 15.4 自動切り替え設定

```yaml
# config/effects.yaml
effects:
  blur:
    backend: "cpp"  # "python" or "cpp"
    params:
      kernel_size: 21
      use_gpu: true
      
  mosaic:
    backend: "python"
    params:
      block_size: 10
```

- **差し替え方法**：設定ファイル or ENV で `fx_backend=cpp` にするだけ。
- **バッチAPI**：`apply_batch(frames, masks, params)` を必ず用意し、C++側でSIMD/GPU最適化。

### 15.5 段階的リファクタリング手順

#### Phase 1: Port定義と既存コードのAdapter化（1週間）
1. `src/domain/ports/` にすべてのインターフェースを定義
2. 既存の実装クラスを `src/adapters/` に移動し、Portを実装
3. DTOクラスを `src/domain/dto/` に定義

#### Phase 2: DIコンテナ導入（3日）
1. `src/infrastructure/di_container.py` を実装
2. 設定ファイルベースの登録メカニズムを構築
3. メインアプリケーションでコンテナを初期化

#### Phase 3: 既存UIの更新（1週間）
1. UIコンポーネントをPort経由でのアクセスに変更
2. 直接的な実装クラスのimportを削除
3. DIコンテナからの依存性注入に変更

#### Phase 4: C++実装の追加（各コンポーネント1-2週間）
1. pybind11環境のセットアップ
2. 優先度の高いコンポーネントから順次C++実装
3. Python実装と並行して動作確認

#### Phase 5: パフォーマンステストと最適化（継続的）
1. A/Bテストによる性能比較
2. ボトルネックの特定と最適化
3. 本番環境での段階的切り替え

---

## 16. シーケンス例（非破壊レンダリング・プレビュー）

```
yaml
コピーする編集する
User → UI → Core: "Export Preview"
Core → Media I/O: decode frames (low-res)
Core → FX Engine: apply mosaic/blur (preview strength)
Core → QC Service: log hash/ΔE00 (optional for preview)
Core → Media I/O: mux preview video (audio stream copy)
UI ← Core: preview file path

```

（FR26, FR28, FR32 を満たす流れ）  

---

## 17. テスト & 品質保証

- **自動検証スクリプト**（FFmpeg/FFprobe + 差分比較）で品質チェック可能に。
- **受入れ基準をテスト化**：PCM MD5一致、ΔE00=0、PTS≤0.5ms、フィールドオーダー維持。